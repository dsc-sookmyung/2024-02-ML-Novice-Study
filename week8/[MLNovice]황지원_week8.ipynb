{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMrIgdGhNXr0VrXkQp6YpAN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"3aYY73BdpXJE"},"outputs":[],"source":["# 순환 신경망으로 IMDB 리뷰 분류하기"]},{"cell_type":"code","source":["# IMDB 리뷰 데이터셋 불러오기\n","from tensorflow.keras.datasets import imdb\n","(train_input, train_target), (test_input, test_target) = imdb.load_data(num_words=200)\n","\n","# train, test set 설정\n","from sklearn.model_selection import train_test_split\n","train_input, val_input, train_target, val_target = train_test_split(train_input, train_target, test_size=0.2, random_state=42)\n","\n","# 리뷰 길이 시각화\n","import matplotlib.pyplot as plt\n","\n","plt.hist(lengths)\n","plt.xlabel('length')\n","plt.ylabel('frequency')\n","plt.show()"],"metadata":{"id":"skd11nHjpZqi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 시퀀스 패딩\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","train_seq = pad_sequences(train_input, maxlen=100)\n","# 100보다 긴 리뷰는 자르고, 100보다 짧은 리뷰는 100으로 패딩"],"metadata":{"id":"h8bPpFaspZso"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 순환 신경망 만들기\n","from tensorflow import keras\n","\n","model = keras.Sequential()\n","\n","model.add(keras.layers.SimpleRNN(8, input_shape=(100, 200)))\n","model.add(keras.layers.Dense(1, activation='sigmoid'))\n","\n","train_oh = keras.utils.to_categorical(train_seq)\n","\n","val_oh = keras.utils.to_categorical(val_seq)\n","model.summary()"],"metadata":{"id":"07wvb3FV2Vuq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모델 훈련\n","rmsprop = keras.optimizers.RMSprop(learning_rate=1e-4)\n","model.compile(optimizer=rmsprop, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","checkpoint_cb = keras.callbacks.ModelCheckpoint('best-simplernn-model.keras', save_best_only=True)\n","early_stopping_cb = keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n","\n","history = model.fit(train_oh, train_target, epochs=100, batch_size=64, validation_data=(val_oh, val_target),\n","callbacks=[checkpoint_cb, early_stopping_cb])\n","\n","# 성능 평가\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.xlabel('epoch')\n","plt.ylabel('loss')\n","plt.legend(['train', 'val'])\n","plt.show()"],"metadata":{"id":"NFxdY1NO2VxQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 임베딩 사용 모델\n","model2 = keras.Sequential()\n","\n","model2.add(keras.layers.Embedding(200, 16, input_shape=(100,)))\n","model2.add(keras.layers.SimpleRNN(8))\n","model2.add(keras.layers.Dense(1, activation='sigmoid'))\n","\n","model2.summary()"],"metadata":{"id":"QfqCQ9SW2Vzw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모델 훈련\n","rmsprop = keras.optimizers.RMSprop(learning_rate=1e-4)\n","model2.compile(optimizer=rmsprop, loss='binary_crossentropy',\n","               metrics=['accuracy'])\n","\n","checkpoint_cb = keras.callbacks.ModelCheckpoint('best-embedding-model.keras', save_best_only=True)\n","early_stopping_cb = keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n","\n","history = model2.fit(train_seq, train_target, epochs=100, batch_size=64, validation_data=(val_seq, val_target),\n","callbacks=[checkpoint_cb, early_stopping_cb])\n","\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.xlabel('epoch')\n","plt.ylabel('loss')\n","plt.legend(['train', 'val'])\n","plt.show()"],"metadata":{"id":"xB1NEr8RpZu7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# LSTM과 GRU 셀"],"metadata":{"id":"NJJ1DYp72gN_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# LSTM 신경망 훈련하기\n","from tensorflow.keras.datasets import imdb\n","from sklearn.model_selection import train_test_split\n","\n","(train_input, train_target), (test_input, test_target) = imdb.load_data(num_words=500)\n","train_input, val_input, train_target, val_target = train_test_split(train_input, train_target, test_size=0.2, random_state=42)\n","\n","\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","train_seq = pad_sequences(train_input, maxlen=100)\n","val_seq = pad_sequences(val_input, maxlen=100)"],"metadata":{"id":"3VeHwT612gQ1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모델 만들기 (keras에서 RNN을 LSTM으로 바꾸면 됨)\n","from tensorflow import keras\n","\n","model = keras.Sequential()\n","\n","model.add(keras.layers.Embedding(500, 16, input_shape=(100,)))\n","model.add(keras.layers.LSTM(8))\n","model.add(keras.layers.Dense(1, activation='sigmoid'))\n","\n","model.summary()"],"metadata":{"id":"P87IZIAs3j2V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모델 훈련\n","rmsprop = keras.optimizers.RMSprop(learning_rate=1e-4)\n","model.compile(optimizer=rmsprop, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","checkpoint_cb = keras.callbacks.ModelCheckpoint('best-lstm-model.keras', save_best_only=True)\n","early_stopping_cb = keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n","\n","history = model.fit(train_seq, train_target, epochs=100, batch_size=64,\n","                    validation_data=(val_seq, val_target),\n","                    callbacks=[checkpoint_cb, early_stopping_cb])"],"metadata":{"id":"PsMwgtkL6QVM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 성능 평가\n","import matplotlib.pyplot as plt\n","\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.xlabel('epoch')\n","plt.ylabel('loss')\n","plt.legend(['train', 'val'])\n","plt.show()"],"metadata":{"id":"7JgudiBv3j5R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 순환 층에 드롭아웃 적용하기\n","model2 = keras.Sequential()\n","\n","model2.add(keras.layers.Embedding(500, 16, input_shape=(100,)))\n","model2.add(keras.layers.LSTM(8, dropout=0.3))\n","model2.add(keras.layers.Dense(1, activation='sigmoid'))"],"metadata":{"id":"FjAaqHXp6TgE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 2개의 층을 연결하기\n","model3 = keras.Sequential()\n","\n","model3.add(keras.layers.Embedding(500, 16, input_shape=(100,)))\n","model3.add(keras.layers.LSTM(8, dropout=0.3, return_sequences=True)) # return_sequences=True 기억하기\n","model3.add(keras.layers.LSTM(8, dropout=0.3))\n","model3.add(keras.layers.Dense(1, activation='sigmoid'))\n","\n","model3.summary()"],"metadata":{"id":"HgpUGpro6Tiz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# GRU 신경망 훈련하기\n","model4 = keras.Sequential()\n","\n","model4.add(keras.layers.Embedding(500, 16, input_shape=(100,)))\n","model4.add(keras.layers.GRU(8))\n","model4.add(keras.layers.Dense(1, activation='sigmoid'))\n","\n","model4.summary()"],"metadata":{"id":"56W6-nEx6X4r"},"execution_count":null,"outputs":[]}]}